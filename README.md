# ğŸ¤– AI-Native 5G Base Station Receiver Trained with a Digital Twin

ğŸ“ Senior Design / Honors Project â€” UT Austin  
ğŸ‘¨â€ğŸ« Advisor: Prof. Kaushik Chowdhury  

---

## ğŸ“Œ Overview
This project studies how an **AI-native 5G receiver** compares to a **traditional signal-processing receiver** when evaluated using a **realistic digital twin** of the UT Austin campus.

Instead of relying on simplified wireless channel models, we use physics-based simulation to better understand how receivers behave in real-world environments.

---

## ğŸ’¡ Motivation (Why)
Wireless systems are often designed and tested under ideal assumptions that donâ€™t fully capture real-world effects like:
- multipath propagation  
- blockage from buildings  
- interference from nearby transmitters  

The goal of this project is to explore whether **machine-learning-based receivers**, when trained on realistic digital-twin-generated data, can adapt better to these conditions than classical approaches.

---

## ğŸ§  System Design (What)
The system is designed as an end-to-end evaluation pipeline that includes:
- ğŸ™ï¸ A 3D digital twin of the UT Austin campus  
- ğŸ“¡ Physics-based wireless channel simulation  
- ğŸ“Š A traditional 5G receiver baseline  
- ğŸ¤– An AI-native receiver architecture  
- ğŸ§ª Hardware-in-the-loop validation using a channel emulator  

---

## ğŸ› ï¸ The Process (How)

### ğŸ—ï¸ Digital Twin & Channel Simulation
- Imported campus geometry using **OpenStreetMap** and **LiDAR data**
- Built a ray-tracing-based simulation environment using **NVIDIA Sionna**
- Generated channel impulse and frequency responses for different transmitterâ€“receiver locations
- Verified that simulated propagation behavior matched expected physical trends

### ğŸ“¶ Traditional Receiver Baseline
- Studied and implemented a classical 5G receiver chain
- Analyzed synchronization, channel estimation, equalization, and decoding stages
- Defined evaluation metrics such as **BER**, **BLER**, and **throughput** based on 3GPP standards

### ğŸ¤– AI-Native Receiver Design
- Designed an ML-based receiver intended to replace parts of the classical decoding pipeline
- Defined data generation and training workflows using digital-twin-simulated channels
- Planned integration with **Keysight Propsim** and **OpenAirInterface** for testbed evaluation

---

## ğŸš¦ Current Status
âœ” Digital twin creation pipeline validated  
âœ” Ray-tracing-based channel simulations verified  
âœ” Traditional receiver baseline established  
âœ” System architecture and evaluation plan defined  
â³ AI model training and hardware integration in progress  

This repository documents the **system design, simulation validation, and risk reduction work** completed so far.

---

## ğŸ§° Tools & Technologies
- âš¡ NVIDIA Sionna (ray tracing & channel modeling)  
- ğŸ Python  
- ğŸ§  Machine learning frameworks (planned)  
- ğŸ“¡ OpenAirInterface (5G stack)  
- ğŸ§ª Keysight Propsim (channel emulation)  
- ğŸ—ºï¸ OpenStreetMap & LiDAR data  

---

## ğŸ“ What I Learned
- How to translate wireless theory into a simulation-driven system design  
- How realistic channel modeling changes receiver behavior compared to idealized models  
- The importance of validating system components before full hardware deployment  
- How to fairly compare AI-based receivers with classical signal-processing methods  

---

## ğŸš€ Next Steps
- Train AI-native receiver models using digital-twin-generated datasets  
- Integrate both receivers into a hardware testbed  
- Compare performance under interference, mobility, and multipath conditions
